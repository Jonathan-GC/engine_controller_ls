{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "from math import ceil,floor\n",
    " \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PongAgent:\n",
    "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
    "\n",
    "        #Creacion de tabla de politicas\n",
    "        if policy is not None:\n",
    "            self._q_table = policy\n",
    "        else:\n",
    "            position = list(game.positions_space.shape)\n",
    "            position.append(len(game.action_space))\n",
    "            self._q_table = np.zeros(position)\n",
    "\n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.ratio_explotacion = ratio_explotacion\n",
    "\n",
    "    def get_next_step(self, state, game):\n",
    "        #damos un paso aleatorio\n",
    "        next_step = np.random.choice(list(game.action_space))\n",
    "\n",
    "        # o tomaremos el mejor paso\n",
    "        if np.random.uniform() <= self.ratio_explotacion:\n",
    "            #Tomar el maximo\n",
    "            idx_action = np.random.choice(np.flatnonzero(\n",
    "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
    "                ))\n",
    "            next_step = list(game.action_space)[idx_action]\n",
    "\n",
    "        return next_step\n",
    "    \n",
    "    # actualizamos las politicas con las recompensas obtenidas\n",
    "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
    "        idx_action_taken =list(game.action_space).index(action_taken)\n",
    " \n",
    "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
    "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
    " \n",
    "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
    "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
    "        if reached_end:\n",
    "            future_max_q_value = reward_action_taken #maximum reward\n",
    " \n",
    "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
    "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
    "    \n",
    "    def print_policy(self):\n",
    "        for row in np.round(self._q_table,1):\n",
    "            for column in row:\n",
    "                print('[', end='')\n",
    "                for value in column:\n",
    "                    print(str(value).zfill(5), end=' ')\n",
    "                print('] ', end='')\n",
    "            print('')\n",
    "            \n",
    "    def get_policy(self):\n",
    "        return self._q_table\n",
    "    \n",
    "class PongEnvironment:\n",
    "    \n",
    "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
    "        \n",
    "        self.action_space = ['Arriba','Abajo']\n",
    "        \n",
    "        self._step_penalization = 0\n",
    "        \n",
    "        self.state = [0,0,0]\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        \n",
    "        self.dx = movimiento_px\n",
    "        self.dy = movimiento_px\n",
    "        \n",
    "        filas = ceil(height_px/movimiento_px)\n",
    "        columnas = ceil(width_px/movimiento_px)\n",
    "        \n",
    "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
    "                                                  for y in range(filas)] \n",
    "                                                     for x in range(filas)])\n",
    " \n",
    "        self.lives = max_life\n",
    "        self.max_life=max_life\n",
    "        \n",
    "        self.x = randint(int(width_px/2), width_px) \n",
    "        self.y = randint(0, height_px-10)\n",
    "        \n",
    "        self.player_alto = int(height_px/4)\n",
    " \n",
    "        self.player1 = self.player_alto  # posic. inicial del player\n",
    "        \n",
    "        self.score = 0\n",
    "        \n",
    "        self.width_px = width_px\n",
    "        self.height_px = height_px\n",
    "        self.radio = 2.5\n",
    " \n",
    "    def reset(self):\n",
    "        self.total_reward = 0\n",
    "        self.state = [0,0,0]\n",
    "        self.lives = self.max_life\n",
    "        self.score = 0\n",
    "        self.x = randint(int(self.width_px/2), self.width_px) \n",
    "        self.y = randint(0, self.height_px-10)\n",
    "        return self.state\n",
    " \n",
    "    def step(self, action, animate=False):\n",
    "        self._apply_action(action, animate)\n",
    "        done = self.lives <=0 # final\n",
    "        reward = self.score\n",
    "        reward += self._step_penalization\n",
    "        self.total_reward += reward\n",
    "        return self.state, reward , done\n",
    " \n",
    "    def _apply_action(self, action, animate=False):\n",
    "        \n",
    "        if action == \"Arriba\":\n",
    "            self.player1 += abs(self.dy)\n",
    "        elif action == \"Abajo\":\n",
    "            self.player1 -= abs(self.dy)\n",
    "            \n",
    "        self.avanza_player()\n",
    " \n",
    "        self.avanza_frame()\n",
    " \n",
    "        if animate:\n",
    "            clear_output(wait=True);\n",
    "            fig = self.dibujar_frame()\n",
    "            plt.show()\n",
    " \n",
    "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
    "    \n",
    "    def detectaColision(self, ball_y, player_y):\n",
    "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def avanza_player(self):\n",
    "        if self.player1 + self.player_alto >= self.height_px:\n",
    "            self.player1 = self.height_px - self.player_alto\n",
    "        elif self.player1 <= -abs(self.dy):\n",
    "            self.player1 = -abs(self.dy)\n",
    " \n",
    "    def avanza_frame(self):\n",
    "        self.x += self.dx\n",
    "        self.y += self.dy\n",
    "        if self.x <= 3 or self.x > self.width_px:\n",
    "            self.dx = -self.dx\n",
    "            if self.x <= 3:\n",
    "                ret = self.detectaColision(self.y, self.player1)\n",
    " \n",
    "                if ret:\n",
    "                    self.score = 10\n",
    "                else:\n",
    "                    self.score = -10\n",
    "                    self.lives -= 1\n",
    "                    if self.lives>0:\n",
    "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
    "                        self.y = randint(0, self.height_px-10)\n",
    "                        self.dx = abs(self.dx)\n",
    "                        self.dy = abs(self.dy)\n",
    "        else:\n",
    "            self.score = 0\n",
    " \n",
    "        if self.y < 0 or self.y > self.height_px:\n",
    "            self.dy = -self.dy\n",
    " \n",
    "    def dibujar_frame(self):\n",
    "        fig = plt.figure(figsize=(5, 4))\n",
    "        a1 = plt.gca()\n",
    "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
    "        a1.set_ylim(-5, self.height_px+5)\n",
    "        a1.set_xlim(-5, self.width_px+5)\n",
    " \n",
    "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
    "        a1.add_patch(circle);\n",
    "        a1.add_patch(rectangle)\n",
    "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
    "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
    "        if self.lives <=0:\n",
    "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
    "        elif self.total_reward >= 1000:\n",
    "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
    "        return fig\n",
    " \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
    "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
    " \n",
    "    if game is None:\n",
    "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
    "        \n",
    "    if learner is None:\n",
    "        print(\"Begin new Train!\")\n",
    "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
    " \n",
    "    max_points= -9999\n",
    "    first_max_reached = 0\n",
    "    total_rw=0\n",
    "    steps=[]\n",
    " \n",
    "    for played_games in range(0, rounds):\n",
    "        state = game.reset()\n",
    "        reward, done = None, None\n",
    "        \n",
    "        itera=0\n",
    "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
    "            old_state = np.array(state)\n",
    "            next_action = learner.get_next_step(state, game)\n",
    "            state, reward, done = game.step(next_action, animate=animate)\n",
    "            if rounds > 1:\n",
    "                learner.update(game, old_state, next_action, reward, state, done)\n",
    "            itera+=1\n",
    "        \n",
    "        steps.append(itera)\n",
    "        \n",
    "        total_rw+=game.total_reward\n",
    "        if game.total_reward > max_points:\n",
    "            max_points=game.total_reward\n",
    "            first_max_reached = played_games\n",
    "        \n",
    "        if played_games %500==0 and played_games >1 and not animate:\n",
    "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
    "                \n",
    "    if played_games>1:\n",
    "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
    "        \n",
    "    #learner.print_policy()\n",
    "    \n",
    "    return learner, game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin new Train!\n",
      "-- Partidas[ 500 ] Avg.Puntos[ 14 ]  AVG Steps[ 218 ] Max Score[ 180 ]\n",
      "-- Partidas[ 1000 ] Avg.Puntos[ 19 ]  AVG Steps[ 237 ] Max Score[ 200 ]\n",
      "-- Partidas[ 1500 ] Avg.Puntos[ 24 ]  AVG Steps[ 254 ] Max Score[ 310 ]\n",
      "-- Partidas[ 2000 ] Avg.Puntos[ 24 ]  AVG Steps[ 254 ] Max Score[ 310 ]\n",
      "-- Partidas[ 2500 ] Avg.Puntos[ 25 ]  AVG Steps[ 257 ] Max Score[ 310 ]\n",
      "-- Partidas[ 3000 ] Avg.Puntos[ 28 ]  AVG Steps[ 265 ] Max Score[ 360 ]\n",
      "-- Partidas[ 3500 ] Avg.Puntos[ 31 ]  AVG Steps[ 277 ] Max Score[ 480 ]\n",
      "-- Partidas[ 4000 ] Avg.Puntos[ 35 ]  AVG Steps[ 289 ] Max Score[ 480 ]\n",
      "-- Partidas[ 4500 ] Avg.Puntos[ 36 ]  AVG Steps[ 295 ] Max Score[ 480 ]\n",
      "-- Partidas[ 5000 ] Avg.Puntos[ 37 ]  AVG Steps[ 298 ] Max Score[ 480 ]\n",
      "-- Partidas[ 5500 ] Avg.Puntos[ 39 ]  AVG Steps[ 304 ] Max Score[ 480 ]\n",
      "-- Partidas[ 6000 ] Avg.Puntos[ 40 ]  AVG Steps[ 306 ] Max Score[ 480 ]\n",
      "-- Partidas[ 6500 ] Avg.Puntos[ 41 ]  AVG Steps[ 310 ] Max Score[ 480 ]\n",
      "-- Partidas[ 7000 ] Avg.Puntos[ 42 ]  AVG Steps[ 312 ] Max Score[ 480 ]\n",
      "-- Partidas[ 7500 ] Avg.Puntos[ 43 ]  AVG Steps[ 317 ] Max Score[ 630 ]\n",
      "-- Partidas[ 8000 ] Avg.Puntos[ 43 ]  AVG Steps[ 318 ] Max Score[ 630 ]\n",
      "-- Partidas[ 8500 ] Avg.Puntos[ 44 ]  AVG Steps[ 320 ] Max Score[ 630 ]\n",
      "-- Partidas[ 9000 ] Avg.Puntos[ 45 ]  AVG Steps[ 323 ] Max Score[ 630 ]\n",
      "-- Partidas[ 9500 ] Avg.Puntos[ 45 ]  AVG Steps[ 325 ] Max Score[ 630 ]\n",
      "-- Partidas[ 10000 ] Avg.Puntos[ 46 ]  AVG Steps[ 325 ] Max Score[ 630 ]\n",
      "-- Partidas[ 10500 ] Avg.Puntos[ 46 ]  AVG Steps[ 326 ] Max Score[ 630 ]\n",
      "-- Partidas[ 11000 ] Avg.Puntos[ 46 ]  AVG Steps[ 327 ] Max Score[ 630 ]\n",
      "-- Partidas[ 11500 ] Avg.Puntos[ 46 ]  AVG Steps[ 327 ] Max Score[ 630 ]\n",
      "-- Partidas[ 12000 ] Avg.Puntos[ 46 ]  AVG Steps[ 327 ] Max Score[ 630 ]\n",
      "-- Partidas[ 12500 ] Avg.Puntos[ 46 ]  AVG Steps[ 329 ] Max Score[ 630 ]\n",
      "-- Partidas[ 13000 ] Avg.Puntos[ 47 ]  AVG Steps[ 330 ] Max Score[ 630 ]\n",
      "-- Partidas[ 13500 ] Avg.Puntos[ 47 ]  AVG Steps[ 331 ] Max Score[ 630 ]\n",
      "-- Partidas[ 14000 ] Avg.Puntos[ 47 ]  AVG Steps[ 332 ] Max Score[ 630 ]\n",
      "-- Partidas[ 14500 ] Avg.Puntos[ 48 ]  AVG Steps[ 334 ] Max Score[ 630 ]\n",
      "-- Partidas[ 15000 ] Avg.Puntos[ 48 ]  AVG Steps[ 334 ] Max Score[ 630 ]\n",
      "-- Partidas[ 15500 ] Avg.Puntos[ 49 ]  AVG Steps[ 336 ] Max Score[ 630 ]\n",
      "-- Partidas[ 16000 ] Avg.Puntos[ 49 ]  AVG Steps[ 338 ] Max Score[ 630 ]\n",
      "-- Partidas[ 16500 ] Avg.Puntos[ 49 ]  AVG Steps[ 339 ] Max Score[ 630 ]\n",
      "-- Partidas[ 17000 ] Avg.Puntos[ 50 ]  AVG Steps[ 339 ] Max Score[ 650 ]\n",
      "-- Partidas[ 17500 ] Avg.Puntos[ 50 ]  AVG Steps[ 340 ] Max Score[ 760 ]\n",
      "-- Partidas[ 18000 ] Avg.Puntos[ 50 ]  AVG Steps[ 341 ] Max Score[ 760 ]\n",
      "-- Partidas[ 18500 ] Avg.Puntos[ 50 ]  AVG Steps[ 341 ] Max Score[ 760 ]\n",
      "-- Partidas[ 19000 ] Avg.Puntos[ 51 ]  AVG Steps[ 343 ] Max Score[ 760 ]\n",
      "-- Partidas[ 19500 ] Avg.Puntos[ 51 ]  AVG Steps[ 345 ] Max Score[ 760 ]\n",
      "Partidas[ 19999 ] Avg.Puntos[ 51 ] Max score[ 760 ] en partida[ 17341 ]\n"
     ]
    }
   ],
   "source": [
    "learner, game = play(rounds=20000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner2 = PongAgent(game, policy=learner.get_policy())\n",
    "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
    "player = play(rounds=1, learner=learner2, game=game, animate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maquina7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
